{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/u/cs451/packages/spark\")\n",
    "\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once Python knows where Spark is located, you can create a `SparkContext`.   All Spark commands must run within an active `SparkContext`.   The code below will create a `SparkContext`, and store a reference to the context in the variable `sc`. \n",
    "The `appName` parameter assigns a name of your choosing to the Spark jobs that are created in this context - this is useful mostly for debugging.   The `master` parameter indicates that Spark jobs will run in local mode, using two threads.   This means that your Spark jobs are not really running on a cluster (since we do not have a Spark cluster in the CS student computing environment), and are instead running in a single process on the local machine.   You program Spark jobs the same way whether they run in local mode or on a cluster - the main difference between local and cluster modes is, of course, performance.\n",
    "\n",
    "Run the code in the cell below to create a Spark context.   Creating the `SparkContext` causes your Python program (running in this notebook) to prepare to run Spark jobs, and will take a few seconds to complete.  Be sure that you run this code only one time, because a single Python program may only have one active SparkContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"YourTest\", master=\"local[2]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's test that your `SparkContext` has been set up properly by running some simple test code (adapted from the [Spark examples page](https://spark.apache.org/examples.html)).   This code uses a single Spark job to estimate the value of $\\pi$.  `parallelize()` and `filter()` are Spark *transformations*, and `count()` is a Spark *action*.   Study the code in the cell below, then go ahead and run it.   It should take a few seconds, since a Spark job is being created and executed, and should print an estimate of $\\pi$ when it finishes.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14193344\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi_estimate = 4 * count / num_samples\n",
    "print(pi_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Briefly explain how the $\\pi$-estimation example works.   What is the Spark job doing, and how is it used to estimate the value of $\\pi$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your answer to Question 1:\n",
    "\n",
    "Suppose the first quadrant is the square with 0 <= x <= 1 and 0 <= y <= 1.\n",
    "\n",
    "The spark job takes 100000000 random samples of pairs of (x,y) data in the first quadrant using random.random(), where random.random() generates a random float uniformly in the semi-open range [0.0, 1.0)\n",
    "\n",
    "Out of the 100000000 random samples, count those pairs that satisfy x^2 + y^2 < 1, which are points in the first quadrant that are in the quarter of a circle with radius 1\n",
    "\n",
    "Now the ratio of all the points that satisfy x^2 + y^2 < 1 over the all the points in the first quadrant with side length = 1, will be roughly the same as the ratio of an area of a circle with radius 1 over a square with sidelength = 2. \n",
    "\n",
    "In equation form, this will be\n",
    "\n",
    "$\\frac{\\pi r^2}{2^2} \\approx \\frac{\\text{count of all points that satisfy x^2 + y^2 < 1 in first quadrant}}{ \\text{all the points in the first quadrant}}$\n",
    "\n",
    "where r = 1\n",
    "\n",
    "hence\n",
    "\n",
    "$\\pi \\approx 4*\\frac{\\text{count of all points that satisfy x^2 + y^2 < 1 in first quadrant}}{\\text{all the points in the first quadrant}}$\n",
    "\n",
    "which is what the spark job is doing to estimate  $\\pi$\n",
    "\n",
    "In Steps:\n",
    "\n",
    "1. sc.parallelize turns range(0,num_samples) into an RDD\n",
    "2. on top of the RDD, filtered using the function *inside* and only those points that satisfy x^2 + y^2 < 1 were counted.\n",
    "3. $\\pi$ was estimated using the equation $\\pi \\approx 4*\\frac{\\text{count of all points that satisfy x^2 + y^2 < 1 in first quadrant}}{\\text{all the points in the first quadrant}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Important\n",
    "\n",
    "###### The questions that follow ask you to implement functions whose prototypes are given to you. Do **NOT** change the prototypes of the functions. Do **NOT** write code outside of the functions. All necessary code should be included in the function body (except for import statements). You may declare functions inside of the function body. When marking, we will execute your code by calling the functions from an external program, which is why your code cannot rely on statements running outside functions. Please remove any call to the functions that you may have introduced for test purposes before submitting your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now it is your turn to write some Spark programs. Start with the simple task of counting the number of *distinct* tokens which appear in `Shakespeare.txt`.   You have already written Python code to do this in Assignment 1, but for this assignment we want you to use Spark to solve the same problem.   You should compare the answer you get using Spark with the answer you got from your pure-Python solution from Assignment 1.   Both answers should, of course, be the same.\n",
    "\n",
    "Your code should use Spark, not the Python driver code, to read `Shakespeare.txt` and do the counting.   The idea is to use Spark to give you a data-parallel alternative to the sequential Python solution you wrote for Assignment 1.\n",
    "\n",
    "Write your solution for question 2 in the code cell below, by implementing the `count_distinct_tokens` function. It should use the `SparkContext` which was created previously (referenced by the variable `sc`). The function `count_distinct_tokens` must return the number of distinct tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_tokenize import simple_tokenize\n",
    "\n",
    "# Returns the count of distinct tokens in the `Shakespeare.txt` dataset\n",
    "def count_distinct_tokens():\n",
    "    # read lines\n",
    "    lines = sc.textFile(\"Shakespeare.txt\")\n",
    "    # tokenize, map, reduce and count\n",
    "    count = lines.flatMap(lambda line: simple_tokenize(line)) \\\n",
    "    .map(lambda word: (word, 1)) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .count()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "count_distinct_tokens() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next, write a Spark program that will count the number of distinct token pairs in `Shakespeare.txt`, as you did in Assignment 1. Again, ensure that the answer that you get using Spark matches the answer you got in the first assignment.\n",
    "\n",
    "Write your solution for question 3 by implementing the `count_distinct_pairs` function in the code cell below.   It should use the `SparkContext` which was created previously (referenced by the variable `sc`). The function `count_distinct_pairs` must return the number of distinct token pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_tokenize import simple_tokenize\n",
    "\n",
    "# Returns the count of distinct pairs in the `Shakespeare.txt` dataset\n",
    "def count_distinct_pairs():\n",
    "    # a pairs helper function\n",
    "    def pairs(line):\n",
    "        result = []\n",
    "        for i in line:\n",
    "            for j in line:\n",
    "                if i != j:\n",
    "                    result.append((i,j))\n",
    "        return result\n",
    "    # read file\n",
    "    lines = sc.textFile(\"Shakespeare.txt\")\n",
    "    # tokenize, use pairs as keys, map, reduce and count\n",
    "    count = lines.map(lambda line: simple_tokenize(line))\\\n",
    "                .flatMap(lambda x: pairs(x))\\\n",
    "                .map(lambda word: (word, 1)) \\\n",
    "                .reduceByKey(lambda x,y: x+y) \\\n",
    "                .count()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1969760"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "count_distinct_pairs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next, write Spark code that will calculate the probability $p(x)$ (as defined in Assignment 1) for every distinct token $x$ in `Shakespeare.txt`.   Your function should return the 50 highest-probability tokens, and their counts and probabilities.\n",
    "\n",
    "Make sure that your solution calculates probabilities and identifies the 50 highest-probability tokens in a data-parallel fashion, using Spark transformations and actions.   Only the 50 highest-probability tokens (and their counts and probabilities) should be returned by Spark to your driver code.\n",
    "\n",
    "Write your solution for question 4 by implementing the `top_50_tokens_probabilities` function in the code cell below. It should use the `SparkContext` which was created previously (referenced by the variable `sc`). The function `top_50_tokens_probabilities` must return a list of 50 (probability, count, token) tuples, ordered by probability, that is, the list returned by the function should be of the form: `[(proba1, count1, token1), (proba2, count2, token2), ..., (proba50, count50, token50)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_tokenize import simple_tokenize\n",
    "\n",
    "# Returns a list of the top 50 (probability, count, token) tuples, ordered by probability\n",
    "def top_50_tokens_probabilities():\n",
    "    # read lines\n",
    "    lines = sc.textFile(\"Shakespeare.txt\")\n",
    "    # count total lines\n",
    "    totalLines = lines.count()\n",
    "    # tokenize each line, find unique tokens, map, reduce, sort\n",
    "    count = lines.map(lambda line: simple_tokenize(line))\\\n",
    "                .flatMap(lambda x: set(x))\\\n",
    "                .map(lambda word: (word, (1, 1/totalLines))) \\\n",
    "                .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\\\n",
    "                .map(lambda x:(x[1][1], x[1][0], x[0]))\\\n",
    "                .sortBy(lambda x: x[0],False)            \n",
    "    return count.collect()[:50]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.20091786571727055, 24604, 'and'),\n",
       " (0.1984353819269089, 24300, 'the'),\n",
       " (0.15235427656832087, 18657, 'i'),\n",
       " (0.14892452922637386, 18237, 'to'),\n",
       " (0.13575266622027737, 16624, 'of'),\n",
       " (0.10844534452629928, 13280, 'a'),\n",
       " (0.09959332995803605, 12196, 'you'),\n",
       " (0.09430988583841768, 11549, 'my'),\n",
       " (0.08667461497003565, 10614, 'in'),\n",
       " (0.08630714204054132, 10569, 'that'),\n",
       " (0.07150206601447007, 8756, 'is'),\n",
       " (0.06720671577193643, 8230, 'not'),\n",
       " (0.06167012363422232, 7552, 'with'),\n",
       " (0.06039621747864281, 7396, 'me'),\n",
       " (0.05982459292165162, 7326, 'for'),\n",
       " (0.05836286726877482, 7147, 'it'),\n",
       " (0.0544023256953377, 6662, 'be'),\n",
       " (0.052466968266668426, 6425, 'this'),\n",
       " (0.05228731483447127, 6403, 'his'),\n",
       " (0.05089908376749332, 6233, 'your'),\n",
       " (0.050670433944696947, 6205, 'but'),\n",
       " (0.04749383462084737, 5816, 'he'),\n",
       " (0.046889545803456965, 5742, 'have'),\n",
       " (0.04132028940534538, 5060, 'thou'),\n",
       " (0.04015254209606392, 4917, 'as'),\n",
       " (0.0395237550833739, 4840, 'him'),\n",
       " (0.03949109082297442, 4836, 'so'),\n",
       " (0.03945026049747506, 4831, 'will'),\n",
       " (0.03515491025494326, 4305, 'what'),\n",
       " (0.03122703294190561, 3824, 'all'),\n",
       " (0.03063091018961507, 3751, 'thy'),\n",
       " (0.02971631089842959, 3639, 'by'),\n",
       " (0.02961015205213128, 3626, 'do'),\n",
       " (0.028981365039441258, 3549, 'no'),\n",
       " (0.028858874062943202, 3534, 'shall'),\n",
       " (0.028205588854953577, 3454, 'her'),\n",
       " (0.02816475852945422, 3449, 'if'),\n",
       " (0.026915350569174056, 3296, 'are'),\n",
       " (0.025518953437096224, 3125, 'we'),\n",
       " (0.024890166424406206, 3048, 'thee'),\n",
       " (0.02429404367211567, 2975, 'on'),\n",
       " (0.02403272958891982, 2943, 'lord'),\n",
       " (0.02359992813862669, 2890, 'our'),\n",
       " (0.022946642930636956, 2810, 'king'),\n",
       " (0.02226885952734782, 2727, 'good'),\n",
       " (0.02224436133204821, 2724, 'now'),\n",
       " (0.021468585147560525, 2629, 'sir'),\n",
       " (0.021190938934164932, 2595, 'from'),\n",
       " (0.0206764768328731, 2532, 'o'),\n",
       " (0.020096686210782304, 2461, 'at')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "top_50_tokens_probabilities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next, write the code for the function `PMI` that will take a positive integer threshold $T$ as an argument, and then return all token pairs that co-occur at least $T$ times in `Shakespeare.txt`.   For each such pair $(x,y)$, the function should also return PMI$(x,y)$, the co-occurrence count of the pair, the number of times $x$ appears, and the number of times $y$ appears. You can compare the results produced by this code with the results of Two-Token queries (from Assignment 1) for consistency.\n",
    "\n",
    "Write your solution for question 5 by implementing the function `PMI` in the code cell below. It should use the `SparkContext` which was created previously (referenced by the variable `sc`). The function `PMI` should return a list of ((token1, token2), pmi, co-occurrence_count, token1_count, token2_count) tuples, that is, the list returned by the function should be of the form: `[((token1, token2), pmi, cooc_count, token1_count, token2_count), (...), ((other_token1, other_token2), other_pmi, other_cooc_count, other_token1_count, other_token2_count)]`.\n",
    "\n",
    "\n",
    "As always, calculations should be done in data-parallel fashion by using Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_tokenize import simple_tokenize\n",
    "from math import log\n",
    "\n",
    "# Returns a list of tuples with the following format:\n",
    "# ((token1, token2), pmi, co-occurrence_count, token1_count, token2_count)\n",
    "def PMI(threshold):\n",
    "    # read file\n",
    "    lines = sc.textFile(\"Shakespeare.txt\")\n",
    "    # count total lines\n",
    "    totalLines = lines.count()\n",
    "    # pmi helper function\n",
    "    def pmi(row):\n",
    "        return (row[0],log((row[1][1])/(row[1][3]*row[1][5]),10),row[1][0], row[1][2], row[1][4])\n",
    "    # pairs helper function\n",
    "    def pairs(line):\n",
    "        result = []\n",
    "        for i in line:\n",
    "            for j in line:\n",
    "                if i != j:\n",
    "                    result.append((i,j))\n",
    "        return result\n",
    "    # single token probabilities\n",
    "    probabilities_one = lines.map(lambda line: simple_tokenize(line))\\\n",
    "                .flatMap(lambda x: set(x))\\\n",
    "                .map(lambda word: (word, (1, 1/totalLines))) \\\n",
    "                .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
    "    # pair tokens probabilities\n",
    "    probabilities_two = lines.map(lambda line: simple_tokenize(line))\\\n",
    "                .map(lambda x: pairs(x)).flatMap(lambda x: set(x)).map(lambda t: (t,1))\\\n",
    "                .reduceByKey(lambda x,y: x+y).map(lambda x: (x[0], x[1], x[1]/totalLines))\\\n",
    "                .filter(lambda x: x[1]>=threshold)\n",
    "    # combination probabilities\n",
    "    result = probabilities_two.map(lambda x: (x[0][0], (x[0][1], x[1], x[2])))\\\n",
    "                               .join(probabilities_one)\\\n",
    "                               .map(lambda x: (x[1][0][0], (x[0], x[1][0][1],x[1][0][2], x[1][1])))\\\n",
    "                               .join(probabilities_one)\\\n",
    "                               .map(lambda x: ((x[1][0][0],x[0]), (x[1][0][1],x[1][0][2], x[1][0][3][0], x[1][0][3][1],x[1][1][0],x[1][1][1])))\\\n",
    "                               .map(lambda line: pmi(line))\n",
    "    return result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'of'), 0.34294075191872514, 7266, 24300, 16624),\n",
       " (('and', 'of'), 0.028305447826515007, 3565, 24604, 16624),\n",
       " (('of', 'and'), 0.028305447826515007, 3565, 16624, 24604),\n",
       " (('i', 'and'), -0.05037403533823378, 3338, 18657, 24604),\n",
       " (('the', 'and'), 0.045934991832871336, 5427, 24300, 24604),\n",
       " (('to', 'and'), 0.01752258803852136, 3815, 18237, 24604),\n",
       " (('i', 'to'), 0.04685260592230071, 3095, 18657, 18237),\n",
       " (('the', 'to'), 0.051235259829723094, 4072, 24300, 18237),\n",
       " (('and', 'to'), 0.01752258803852136, 3815, 24604, 18237),\n",
       " (('of', 'the'), 0.34294075191872514, 7266, 16624, 24300),\n",
       " (('i', 'the'), -0.08302344185176173, 3058, 18657, 24300),\n",
       " (('to', 'the'), 0.051235259829723094, 4072, 18237, 24300),\n",
       " (('and', 'the'), 0.045934991832871336, 5427, 24604, 24300),\n",
       " (('the', 'i'), -0.08302344185176173, 3058, 24300, 18657),\n",
       " (('to', 'i'), 0.04685260592230071, 3095, 18237, 18657),\n",
       " (('and', 'i'), -0.05037403533823378, 3338, 24604, 18657)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "PMI(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('the', 'of'), 0.34294075191872514, 7266, 24300, 16624),\n",
       " (('of', 'the'), 0.34294075191872514, 7266, 16624, 24300)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "PMI(6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Finally, write Spark code for the function `PMI_one_token`, that will take a positive integer threshold $T$ and a sample size $N$ as arguments. For every token $x$ in `Shakespeare.txt`, your code should find all tokens $y$ that co-occur with $x$ at least $T$ times, as well as PMI$(x,y)$ for each such pair, the co-occurrence count of the pair, the number of times $x$ appears, and the number of times $y$ appears.\n",
    "\n",
    "For each $x$, the output of your program should be equivalent to the output that would be produced by a One-Token query on $x$ (see Assignment 1), with threshold $T$. Rather than producing output for all possible tokens $x$, the function should produce output only for $N$ different $x$'s, chosen at random from among all distinct tokens in the input file.\n",
    "\n",
    "Write your solution for question 6 by implementing the function `PMI_one_token` in the code cell below. It should use the `SparkContext` which was created previously (referenced by the variable `sc`). The function `PMI_one_token` should return a list of $N$ tuples of the form `(token, [ list_of_cooccurring_tokens ])`, where each entry in `list_of_cooccurring_tokens` is of the form `((token1, token2), pmi, cooc_count, token1_count, token2_count)`.\n",
    "\n",
    "For instance, if $N$ = 2 and the randomly selected tokens are \"if\" and \"you\", a valid format for the value returned by `PMI_one_token` would be:\n",
    "```\n",
    "[('if', [(('if', 'you'), -0.09813466615111513, 1975, 16624, 18237), (('if', 'a'), 0.03856379243802408, 1568, 16624, 10569)]), ('you', [(('you', 'if'), -0.09813466615111513, 1975, 18237, 16624)])]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_tokenize import simple_tokenize\n",
    "from math import log\n",
    "\n",
    "# Returns a list of samp_size tuples with the following format:\n",
    "# (token, [ list_of_cooccurring_tokens ])\n",
    "# where list_of_cooccurring_tokens is of the form\n",
    "# [((token1, token2), pmi, cooc_count, token1_count, token2_count), ...]\n",
    "def PMI_one_token(threshold, samp_size):\n",
    "    lines = sc.textFile(\"Shakespeare.txt\")\n",
    "    totalLines = lines.count()\n",
    "    # pmi helper function\n",
    "    def pmi(row):\n",
    "        return (row[0],log((row[1][1])/(row[1][3]*row[1][5]),10),row[1][0], row[1][2], row[1][4])\n",
    "    # pairs helper function\n",
    "    def pairs(line):\n",
    "        result = []\n",
    "        for i in line:\n",
    "            for j in line:\n",
    "                if i != j:\n",
    "                    result.append((i,j))\n",
    "        return result\n",
    "    # helper for return result\n",
    "    def return_list(x):\n",
    "        if x[1]:\n",
    "            return x[1]\n",
    "        else:\n",
    "            return x[0]    \n",
    "    # single token probabilities\n",
    "    probabilities_one = lines.map(lambda line: simple_tokenize(line))\\\n",
    "            .flatMap(lambda x: set(x))\\\n",
    "            .map(lambda word: (word, (1, 1/totalLines))) \\\n",
    "            .reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
    "    # pair token probabilities\n",
    "    probabilities_two = lines.map(lambda line: simple_tokenize(line))\\\n",
    "                .map(lambda x: pairs(x)).flatMap(lambda x: set(x)).map(lambda t: (t,1))\\\n",
    "                .reduceByKey(lambda x,y: x+y).map(lambda x: (x[0], x[1], x[1]/totalLines))\\\n",
    "                .filter(lambda x: x[1]>=threshold)\n",
    "    # combination probabilities\n",
    "    result = probabilities_two.map(lambda x: (x[0][0], (x[0][1], x[1], x[2])))\\\n",
    "                               .join(probabilities_one)\\\n",
    "                               .map(lambda x: (x[1][0][0], (x[0], x[1][0][1],x[1][0][2], x[1][1])))\\\n",
    "                               .join(probabilities_one)\\\n",
    "                               .map(lambda x: (x[1][0][0], ((x[1][0][0],x[0]), (x[1][0][1],x[1][0][2], x[1][0][3][0], x[1][0][3][1],x[1][1][0],x[1][1][1]))))\\\n",
    "                               .map(lambda line: (line[0], pmi(line[1])))\\\n",
    "                               .groupByKey().mapValues(list)\n",
    "    # final result\n",
    "    return result.takeSample(False, samp_size)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Don't forget to save your workbook!   When you are finished and you are ready to submit your assignment, download your notebook file (.ipynb) from the hub to your machine, and then follow the submission instructions in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wake',\n",
       "  [(('wake', 'we'), 0.3542550516083907, 3, 52, 3125),\n",
       "   (('wake', 'let'), 0.5327153222152776, 3, 52, 2072),\n",
       "   (('wake', 'when'), 0.76238940934359, 5, 52, 2035),\n",
       "   (('wake', 'dost'), 1.0487317183971239, 2, 52, 421),\n",
       "   (('wake', 'king'), 0.4003987533834042, 3, 52, 2810),\n",
       "   (('wake', 'must'), 0.5086609584483545, 2, 52, 1460),\n",
       "   (('wake', 'needs'), 1.5056964794846175, 2, 52, 147),\n",
       "   (('wake', 'pisanio'), 1.6601765895276206, 2, 52, 103),\n",
       "   (('wake', 'that'), -0.17492882461245507, 3, 52, 10569),\n",
       "   (('wake', 'to'), 0.1110304204646305, 10, 52, 18237),\n",
       "   (('wake', 'be'), -0.15059081412234246, 2, 52, 6662),\n",
       "   (('wake', 'and'), 0.23625060532031097, 18, 52, 24604),\n",
       "   (('wake', 'you'), -0.11217360579661026, 4, 52, 12196),\n",
       "   (('wake', 'or'), 0.31393758817353196, 2, 52, 2286),\n",
       "   (('wake', 'if'), 0.43635061552939597, 4, 52, 3449),\n",
       "   (('wake', 'some'), 0.568185410579138, 2, 52, 1273),\n",
       "   (('wake', 'so'), -0.011472477955922775, 2, 52, 4836),\n",
       "   (('wake', 'softly'), 2.3305911334105875, 2, 52, 22),\n",
       "   (('wake', 'but'), -0.1197279716019339, 2, 52, 6205),\n",
       "   (('wake', 'in'), -0.05183527339661751, 4, 52, 10614),\n",
       "   (('wake', 'thou'), 0.2698932930569941, 4, 52, 5060),\n",
       "   (('wake', 'he'), 0.0844806754375138, 3, 52, 5816),\n",
       "   (('wake', 'this'), 0.16617067789346412, 4, 52, 6425),\n",
       "   (('wake', 'do'), 0.28967727352899797, 3, 52, 3626),\n",
       "   (('wake', 'them'), 0.3917531271777771, 2, 52, 1911),\n",
       "   (('wake', 'would'), 0.3247089511846336, 2, 52, 2230),\n",
       "   (('wake', 'asleep'), 1.8948625638491499, 2, 52, 60),\n",
       "   (('wake', 'the'), 0.06555879101802844, 12, 52, 24300),\n",
       "   (('wake', 'it'), -0.18110996786835074, 2, 52, 7147),\n",
       "   (('wake', 'they'), 0.4776677558843763, 3, 52, 2352),\n",
       "   (('wake', 'will'), 0.4660980314659542, 6, 52, 4831),\n",
       "   (('wake', 'with'), 0.09598182860678542, 4, 52, 7552),\n",
       "   (('wake', 'not'), 0.3596739703484971, 8, 52, 8230),\n",
       "   (('wake', 'still'), 0.9287208311101173, 2, 52, 555),\n",
       "   (('wake', 'for'), -0.01576184104002828, 3, 52, 7326),\n",
       "   (('wake', 'all'), 0.26658718968442635, 3, 52, 3824),\n",
       "   (('wake', 'did'), 0.4691653504865559, 2, 52, 1599),\n",
       "   (('wake', 'well'), 0.3413840966028606, 2, 52, 2146),\n",
       "   (('wake', 'patience'), 1.3965520100595488, 2, 52, 189),\n",
       "   (('wake', 'is'), 0.031738057000881996, 4, 52, 8756),\n",
       "   (('wake', 'his'), 0.34375156712830995, 6, 52, 6403),\n",
       "   (('wake', 'i'), 0.277233266091228, 15, 52, 18657),\n",
       "   (('wake', 'her'), 0.5326314896734031, 5, 52, 3454),\n",
       "   (('wake', 'why'), 0.6880366878172984, 3, 52, 1449),\n",
       "   (('wake', 'watch'), 1.4035008700148768, 2, 52, 186),\n",
       "   (('wake', 'peace'), 0.970583277787268, 2, 52, 504),\n",
       "   (('wake', 'a'), -0.05224425212721835, 5, 52, 13280),\n",
       "   (('wake', 'my'), 0.008409441558330661, 5, 52, 11549),\n",
       "   (('wake', 'our'), 0.21211597147625375, 2, 52, 2890),\n",
       "   (('wake', 'him'), 0.2891984482523802, 4, 52, 4840),\n",
       "   (('wake', 'me'), -0.1959830882543207, 2, 52, 7396),\n",
       "   (('wake', 'then'), 0.5076705487103348, 3, 52, 2195),\n",
       "   (('wake', 'shall'), 0.12474726906206075, 2, 52, 3534),\n",
       "   (('wake', 'time'), 0.6501732033562682, 2, 52, 1054),\n",
       "   (('wake', 'thee'), 0.1889988515652399, 2, 52, 3048),\n",
       "   (('wake', 'sleep'), 1.5726432691152297, 4, 52, 252),\n",
       "   (('wake', 'horns'), 1.924825787226593, 2, 52, 56)]),\n",
       " ('envenom', [(('envenom', 'with'), 1.209925180913622, 2, 2, 7552)])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "PMI_one_token(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of',\n",
       "  [(('of', 'to'), -0.09813466615126466, 1975, 16624, 18237),\n",
       "   (('of', 'that'), 0.03856379243792773, 1568, 16624, 10569),\n",
       "   (('of', 'and'), 0.028305447826515007, 3565, 16624, 24604),\n",
       "   (('of', 'you'), -0.060904989766341754, 1439, 16624, 12196),\n",
       "   (('of', 'this'), 0.1517481996162481, 1237, 16624, 6425),\n",
       "   (('of', 'in'), 0.052760101633904634, 1627, 16624, 10614),\n",
       "   (('of', 'the'), 0.34294075191872514, 7266, 16624, 24300),\n",
       "   (('of', 'his'), 0.0799844206133649, 1045, 16624, 6403),\n",
       "   (('of', 'i'), -0.08531809933120071, 2081, 16624, 18657),\n",
       "   (('of', 'is'), 0.020115230526300435, 1245, 16624, 8756),\n",
       "   (('of', 'a'), 0.1355179687974917, 2463, 16624, 13280),\n",
       "   (('of', 'my'), 0.01180279106315552, 1611, 16624, 11549)]),\n",
       " ('but',\n",
       "  [(('but', 'the'), -0.02180400215716167, 1171, 6205, 24300),\n",
       "   (('but', 'i'), 0.16991073624528089, 1398, 6205, 18657)]),\n",
       " ('and',\n",
       "  [(('and', 'of'), 0.028305447826515007, 3565, 24604, 16624),\n",
       "   (('and', 'have'), -0.05220611059650287, 1023, 24604, 5742),\n",
       "   (('and', 'to'), 0.01752258803852136, 3815, 24604, 18237),\n",
       "   (('and', 'that'), -0.058240550309345565, 1857, 24604, 10569),\n",
       "   (('and', 'you'), -0.059634723485062255, 2136, 24604, 12196),\n",
       "   (('and', 'your'), 0.0101723421426252, 1282, 24604, 6233),\n",
       "   (('and', 'be'), 0.0056365050277124695, 1356, 24604, 6662),\n",
       "   (('and', 'so'), 0.03327063985664541, 1049, 24604, 4836),\n",
       "   (('and', 'this'), -0.055895826622365065, 1135, 24604, 6425),\n",
       "   (('and', 'in'), 0.04031821796855459, 2340, 24604, 10614),\n",
       "   (('and', 'he'), 0.030654582495540594, 1254, 24604, 5816),\n",
       "   (('and', 'the'), 0.045934991832871336, 5427, 24604, 24300),\n",
       "   (('and', 'not'), -0.13241468574207282, 1219, 24604, 8230),\n",
       "   (('and', 'will'), 0.044756677695672466, 1076, 24604, 4831),\n",
       "   (('and', 'for'), -0.006218058038963288, 1451, 24604, 7326),\n",
       "   (('and', 'with'), 0.09904235886412223, 1906, 24604, 7552),\n",
       "   (('and', 'it'), 0.020682633615341343, 1506, 24604, 7147),\n",
       "   (('and', 'all'), 0.15821868721643495, 1106, 24604, 3824),\n",
       "   (('and', 'his'), 0.1415056417285139, 1782, 24604, 6403),\n",
       "   (('and', 'i'), -0.05037403533823378, 3338, 24604, 18657),\n",
       "   (('and', 'is'), -0.02705145547264138, 1653, 24604, 8756),\n",
       "   (('and', 'a'), 0.0006198226232624715, 2672, 24604, 13280),\n",
       "   (('and', 'my'), 0.0056896916302427766, 2351, 24604, 11549),\n",
       "   (('and', 'me'), 0.010113755417688091, 1521, 24604, 7396),\n",
       "   (('and', 'him'), 0.08804784369018688, 1191, 24604, 4840)])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "PMI_one_token(1000,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('stinkingly',\n",
       "  [(('stinkingly', 'so'), 1.403500870014895, 1, 1, 4836),\n",
       "   (('stinkingly', 'go'), 1.8647508891006104, 1, 1, 1672),\n",
       "   (('stinkingly', 'mend'), 3.3245591686406737, 1, 1, 58),\n",
       "   (('stinkingly', 'depending'), 4.184897175211667, 1, 1, 8)])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "PMI_one_token(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fighteth',\n",
       "  [(('fighteth', 'as'), 1.396286953913468, 2, 2, 4917),\n",
       "   (('fighteth', 'he'), 1.3233627643526504, 2, 2, 5816)]),\n",
       " ('porn',\n",
       "  [(('porn', 'you'), 0.8256784874545453, 2, 3, 12196),\n",
       "   (('porn', 'he'), 1.1472715052969693, 2, 3, 5816),\n",
       "   (('porn', 'at'), 1.520784289445131, 2, 3, 2461),\n",
       "   (('porn', 'tell'), 1.888231984950139, 2, 3, 1056),\n",
       "   (('porn', 'fluellen'), 3.138597155558698, 3, 3, 89),\n",
       "   (('porn', 'is'), 0.9695901502520373, 2, 3, 8756)]),\n",
       " ('valor',\n",
       "  [(('valor', 'to'), 0.28296571974915397, 2, 7, 18237),\n",
       "   (('valor', 'and'), 0.4539433951655096, 4, 7, 24604),\n",
       "   (('valor', 'the'), 0.15831284425492706, 2, 7, 24300),\n",
       "   (('valor', 'with'), 0.8419483956190277, 3, 7, 7552),\n",
       "   (('valor', 'his'), 0.7375356160291898, 2, 7, 6403)]),\n",
       " ('pinch',\n",
       "  [(('pinch', 'like'), 0.8008351210781057, 3, 33, 1761),\n",
       "   (('pinch', 'let'), 0.5541134669165081, 2, 33, 2072),\n",
       "   (('pinch', 'no'), 0.320397218642125, 2, 33, 3549),\n",
       "   (('pinch', 'as'), 0.5767430183715995, 5, 33, 4917),\n",
       "   (('pinch', 'there'), 0.6217944823887835, 2, 33, 1773),\n",
       "   (('pinch', 'to'), 0.007489828557561095, 5, 33, 18237),\n",
       "   (('pinch', 'and'), 0.21986018913214164, 11, 33, 24604),\n",
       "   (('pinch', 'by'), 0.3095211624034829, 2, 33, 3639),\n",
       "   (('pinch', 'you'), -0.039622938647998394, 3, 33, 12196),\n",
       "   (('pinch', 'your'), 0.25189735015340914, 3, 33, 6233),\n",
       "   (('pinch', 'one'), 0.6364924004025222, 2, 33, 1714),\n",
       "   (('pinch', 'man'), 0.7839061327436863, 3, 33, 1831),\n",
       "   (('pinch', 'blue'), 2.4725632093176677, 2, 33, 25),\n",
       "   (('pinch', 'he'), 0.10587882013874422, 2, 33, 5816),\n",
       "   (('pinch', 'this'), 0.36366008165037583, 4, 33, 6425),\n",
       "   (('pinch', 'more'), 0.8304945819761635, 4, 33, 2193),\n",
       "   (('pinch', 'them'), 0.5892425309346888, 2, 33, 1911),\n",
       "   (('pinch', 'the'), 0.08695693571925878, 8, 33, 24300),\n",
       "   (('pinch', 'they'), 0.6751571596412879, 3, 33, 2352),\n",
       "   (('pinch', 'with'), 0.16853249575539725, 3, 33, 7552),\n",
       "   (('pinch', 'for'), 0.005636303661202099, 2, 33, 7326),\n",
       "   (('pinch', 'hand'), 0.9561600608702677, 2, 33, 821),\n",
       "   (('pinch', 'death'), 0.9385371032615359, 2, 33, 855),\n",
       "   (('pinch', 'within'), 1.1811943588660838, 2, 33, 489),\n",
       "   (('pinch', 'fairies'), 2.2684432266617427, 2, 33, 40),\n",
       "   (('pinch', 'is'), 0.32613747376585006, 5, 33, 8756),\n",
       "   (('pinch', 'his'), 0.2402109752212405, 3, 33, 6403),\n",
       "   (('pinch', 'i'), -0.22424733448787912, 3, 33, 18657),\n",
       "   (('pinch', 'her'), 0.3321808847582772, 2, 33, 3454),\n",
       "   (('pinch', 'doctor'), 1.8330767200490812, 2, 33, 109),\n",
       "   (('pinch', 'a'), 0.2913731873079313, 7, 33, 13280),\n",
       "   (('pinch', 'him'), 0.6627791110649732, 6, 33, 4840),\n",
       "   (('pinch', 'me'), 0.0015063155025909325, 2, 33, 7396),\n",
       "   (('pinch', 'on'), 0.3970162479251456, 2, 33, 2975),\n",
       "   (('pinch', \"they'll\"), 2.1803071379611914, 2, 33, 49)])]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "PMI_one_token(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}